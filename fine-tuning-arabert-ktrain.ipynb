{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# Please see the dataset description for additional info \n# current accuracy (balanced): see last run (this is the AraBERT implementation using ktran)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time \nprint(f'Started: {time.ctime()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U pip\n!pip install \"tensorflow_gpu>=2.0.0\"  # cpu: pip3 install \"tensorflo\n!pip install transformers==2.5.1\n!pip install ktrain ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# restart run time\n#import os\n#def restart_runtime():\n#  os.kill(os.getpid(), 9)\n#restart_runtime()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forked versions of eli5 and stellargraph (required by ktrain)\n!pip install git+https://github.com/amaiya/eli5@tfkeras_0_10_1 \n!pip install git+https://github.com/amaiya/stellargraph@no_tf_dep_082","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth',200)\npd.set_option('display.max_rows',50)\ndf = pd.read_excel('../input/tunisian-texts/tun.xlsx')\ndf['data_labels'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"class_names=['Positive','Negative']\ndf['data_labels'] = df['data_labels'].apply(lambda x: class_names.index(x))\nprint(len(df), '\\n')\ndf.head()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df.sample(frac=0.15, random_state=42)\ndf_train = df.drop(df_test.index)\nlen(df_train), len(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = df_train['texts'].tolist()\ny_train = df_train['data_labels'].to_numpy()\nx_test = df_test['texts'].tolist()\ny_test = df_test['data_labels'].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=df_train[df_train['data_labels']==1]['texts'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='blue')\nax1.set_title('disaster tweets')\ntweet_len=df_test[df_test['data_labels']==0]['texts'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='CRIMSON')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Words in a tweet')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ktrain\nfrom ktrain import text \nMODEL_NAME = 'aubmindlab/bert-base-arabertv01'\nt = text.Transformer(MODEL_NAME, maxlen=90)\n\ntrn = t.preprocess_train(x_train, y_train)\nval = t.preprocess_test(x_test, y_test)\nmodel = t.get_classifier()\nlearner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#takes long time\n#learner.lr_find(show_plot=True, max_epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.autofit(0.1, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.validate(class_names=t.get_classes())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(learner.view_top_losses(n=5, preproc=t)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#n = ?? # from above\n#print(x_test[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_text = '' # enter a review - ex. for printed above\n#predictor = ktrain.get_predictor(learner.model, preproc=t)\n#predictor.predict(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictor.explain(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Finished: {time.ctime()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#https://medium.com/analytics-vidhya/finetuning-bert-using-ktrain-for-disaster-tweets-classification-18f64a50910b"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}